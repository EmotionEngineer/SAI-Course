{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02686264",
   "metadata": {
    "papermill": {
     "duration": 0.007591,
     "end_time": "2024-11-08T10:14:05.890585",
     "exception": false,
     "start_time": "2024-11-08T10:14:05.882994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Geo Housing with LightAutoML\n",
    "\n",
    "This notebook demonstrates how to use `LightAutoML` for automating machine learning tasks. We'll apply it to a housing dataset, focusing on exploratory data analysis, feature engineering, and training a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b4fb4",
   "metadata": {
    "papermill": {
     "duration": 0.006515,
     "end_time": "2024-11-08T10:14:05.904201",
     "exception": false,
     "start_time": "2024-11-08T10:14:05.897686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running the notebook, ensure you have the following libraries installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f389329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:14:05.919650Z",
     "iopub.status.busy": "2024-11-08T10:14:05.919196Z",
     "iopub.status.idle": "2024-11-08T10:17:33.497536Z",
     "shell.execute_reply": "2024-11-08T10:17:33.496294Z"
    },
    "papermill": {
     "duration": 207.589245,
     "end_time": "2024-11-08T10:17:33.500278",
     "exception": false,
     "start_time": "2024-11-08T10:14:05.911033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightautoml\r\n",
      "  Downloading lightautoml-0.3.8.1-py3-none-any.whl.metadata (16 kB)\r\n",
      "Collecting autowoe>=1.2 (from lightautoml)\r\n",
      "  Downloading AutoWoE-1.3.2-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: catboost>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (1.2.7)\r\n",
      "Collecting cmaes (from lightautoml)\r\n",
      "  Downloading cmaes-0.11.1-py3-none-any.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: holidays in /opt/conda/lib/python3.10/site-packages (from lightautoml) (0.57)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (3.1.4)\r\n",
      "Collecting joblib<1.3.0 (from lightautoml)\r\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Collecting json2html (from lightautoml)\r\n",
      "  Downloading json2html-1.3.0.tar.gz (7.0 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting lightgbm<=3.2.1,>=2.3 (from lightautoml)\r\n",
      "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from lightautoml) (3.3)\r\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (1.26.4)\r\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (from lightautoml) (4.0.0)\r\n",
      "Collecting pandas<2.0.0 (from lightautoml)\r\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting poetry-core<2.0.0,>=1.0.0 (from lightautoml)\r\n",
      "  Downloading poetry_core-1.9.1-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from lightautoml) (6.0.2)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.10/site-packages (from lightautoml) (1.2.2)\r\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (from lightautoml) (0.12.2)\r\n",
      "Collecting statsmodels<=0.14.0 (from lightautoml)\r\n",
      "  Downloading statsmodels-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\r\n",
      "Collecting torch<=2.0.0,>=1.9.0 (from lightautoml)\r\n",
      "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from lightautoml) (4.66.4)\r\n",
      "Collecting StrEnum<0.5.0,>=0.4.7 (from autowoe>=1.2->lightautoml)\r\n",
      "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (3.7.5)\r\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (8.3.3)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (2024.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (1.14.1)\r\n",
      "Collecting sphinx (from autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinx-8.1.3-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: sphinx-rtd-theme in /opt/conda/lib/python3.10/site-packages (from autowoe>=1.2->lightautoml) (0.2.4)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml) (0.20.3)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml) (5.22.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost>=0.26.1->lightautoml) (1.16.0)\r\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm<=3.2.1,>=2.3->lightautoml) (0.43.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0->lightautoml) (2.9.0.post0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.22->lightautoml) (3.5.0)\r\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml) (0.5.6)\r\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.10/site-packages (from statsmodels<=0.14.0->lightautoml) (21.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<=2.0.0,>=1.9.0->lightautoml) (1.12)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\r\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\r\n",
      "Collecting triton==2.0.0 (from torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch<=2.0.0,>=1.9.0->lightautoml) (70.0.0)\r\n",
      "Collecting cmake (from triton==2.0.0->torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading cmake-3.30.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\r\n",
      "Collecting lit (from triton==2.0.0->torch<=2.0.0,>=1.9.0->lightautoml)\r\n",
      "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->lightautoml) (2.1.5)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml) (1.13.3)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml) (6.8.2)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna->lightautoml) (2.0.30)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna->lightautoml) (1.3.5)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (10.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (3.1.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna->lightautoml) (3.0.3)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost>=0.26.1->lightautoml) (8.3.0)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (2.0.0)\r\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (1.5.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (1.2.0)\r\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest->autowoe>=1.2->lightautoml) (2.0.1)\r\n",
      "Collecting sphinxcontrib-applehelp>=1.0.7 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-devhelp>=1.0.6 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.6 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-jsmath>=1.0.1 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting sphinxcontrib-qthelp>=1.0.6 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: Pygments>=2.17 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.18.0)\r\n",
      "Collecting docutils<0.22,>=0.20 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: snowballstemmer>=2.2 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.2.0)\r\n",
      "Requirement already satisfied: babel>=2.13 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.15.0)\r\n",
      "Collecting alabaster>=0.7.14 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading alabaster-1.0.0-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting imagesize>=1.3 (from sphinx->autowoe>=1.2->lightautoml)\r\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: requests>=2.30.0 in /opt/conda/lib/python3.10/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.32.3)\r\n",
      "Collecting packaging>=21.3 (from statsmodels<=0.14.0->lightautoml)\r\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<=2.0.0,>=1.9.0->lightautoml) (1.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.30.0->sphinx->autowoe>=1.2->lightautoml) (2024.8.30)\r\n",
      "Downloading lightautoml-0.3.8.1-py3-none-any.whl (416 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.4/416.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading AutoWoE-1.3.2-py3-none-any.whl (215 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.7/215.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading joblib-1.2.0-py3-none-any.whl (297 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading poetry_core-1.9.1-py3-none-any.whl (309 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.5/309.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading statsmodels-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cmaes-0.11.1-py3-none-any.whl (35 kB)\r\n",
      "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\r\n",
      "Downloading sphinx-8.1.3-py3-none-any.whl (3.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading alabaster-1.0.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading docutils-0.21.2-py3-none-any.whl (587 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\r\n",
      "Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\r\n",
      "Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading cmake-3.30.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: json2html\r\n",
      "  Building wheel for json2html (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7593 sha256=adb0637ed4b5c3b4708b00f443560788f3e57fbcd73fba889c696c0c6567a464\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e0/d8/b3/6f83a04ab0ec00e691de794d108286bb0f8bcdf4ade19afb57\r\n",
      "Successfully built json2html\r\n",
      "Installing collected packages: StrEnum, lit, json2html, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, poetry-core, packaging, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, joblib, imagesize, docutils, cmake, cmaes, alabaster, sphinx, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, statsmodels, lightgbm, autowoe, triton, torch, lightautoml\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "  Attempting uninstall: joblib\r\n",
      "    Found existing installation: joblib 1.4.2\r\n",
      "    Uninstalling joblib-1.4.2:\r\n",
      "      Successfully uninstalled joblib-1.4.2\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.2.3\r\n",
      "    Uninstalling pandas-2.2.3:\r\n",
      "      Successfully uninstalled pandas-2.2.3\r\n",
      "  Attempting uninstall: statsmodels\r\n",
      "    Found existing installation: statsmodels 0.14.2\r\n",
      "    Uninstalling statsmodels-0.14.2:\r\n",
      "      Successfully uninstalled statsmodels-0.14.2\r\n",
      "  Attempting uninstall: lightgbm\r\n",
      "    Found existing installation: lightgbm 4.2.0\r\n",
      "    Uninstalling lightgbm-4.2.0:\r\n",
      "      Successfully uninstalled lightgbm-4.2.0\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.4.0+cpu\r\n",
      "    Uninstalling torch-2.4.0+cpu:\r\n",
      "      Successfully uninstalled torch-2.4.0+cpu\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "dask-expr 1.1.15 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\r\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\r\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "pytorch-lightning 2.4.0 requires torch>=2.1.0, but you have torch 2.0.0 which is incompatible.\r\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\r\n",
      "torchaudio 2.4.0+cpu requires torch==2.4.0, but you have torch 2.0.0 which is incompatible.\r\n",
      "torchvision 0.19.0+cpu requires torch==2.4.0, but you have torch 2.0.0 which is incompatible.\r\n",
      "woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\r\n",
      "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\r\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed StrEnum-0.4.15 alabaster-1.0.0 autowoe-1.3.2 cmaes-0.11.1 cmake-3.30.5 docutils-0.21.2 imagesize-1.4.1 joblib-1.2.0 json2html-1.3.0 lightautoml-0.3.8.1 lightgbm-3.2.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 packaging-24.2 pandas-1.5.3 poetry-core-1.9.1 sphinx-8.1.3 sphinxcontrib-applehelp-2.0.0 sphinxcontrib-devhelp-2.0.0 sphinxcontrib-htmlhelp-2.1.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-2.0.0 sphinxcontrib-serializinghtml-2.0.0 statsmodels-0.14.0 torch-2.0.0 triton-2.0.0\r\n",
      "Collecting pandas==1.4.3\r\n",
      "  Downloading pandas-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.4.3) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.4.3) (2024.1)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas==1.4.3) (1.26.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas==1.4.3) (1.16.0)\r\n",
      "Downloading pandas-1.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pandas\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 1.5.3\r\n",
      "    Uninstalling pandas-1.5.3:\r\n",
      "      Successfully uninstalled pandas-1.5.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "arviz 0.20.0 requires pandas>=1.5.0, but you have pandas 1.4.3 which is incompatible.\r\n",
      "beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\r\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 1.4.3 which is incompatible.\r\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "dask-expr 1.1.15 requires pandas>=2, but you have pandas 1.4.3 which is incompatible.\r\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\r\n",
      "featuretools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.4.3 which is incompatible.\r\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.4.3 which is incompatible.\r\n",
      "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.4.3 which is incompatible.\r\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.4.3 which is incompatible.\r\n",
      "woodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.4.3 which is incompatible.\r\n",
      "xarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.4.3 which is incompatible.\r\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed pandas-1.4.3\r\n",
      "Collecting reverse_geocoder\r\n",
      "  Downloading reverse_geocoder-1.5.1.tar.gz (2.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from reverse_geocoder) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=0.17.1 in /opt/conda/lib/python3.10/site-packages (from reverse_geocoder) (1.14.1)\r\n",
      "Building wheels for collected packages: reverse_geocoder\r\n",
      "  Building wheel for reverse_geocoder (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for reverse_geocoder: filename=reverse_geocoder-1.5.1-py3-none-any.whl size=2268063 sha256=88d97b7130fbdedb7afbb3b15ad1c241730fd3bdaa2b563cb3ed1d001ee02241\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/e5/88/eb139b6d6a26b8022d370ab991f7a836802fed9871975ec6d9\r\n",
      "Successfully built reverse_geocoder\r\n",
      "Installing collected packages: reverse_geocoder\r\n",
      "Successfully installed reverse_geocoder-1.5.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install lightautoml\n",
    "!pip install pandas==1.4.3\n",
    "!pip install reverse_geocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab424c19",
   "metadata": {
    "papermill": {
     "duration": 0.076233,
     "end_time": "2024-11-08T10:17:33.653947",
     "exception": false,
     "start_time": "2024-11-08T10:17:33.577714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Importing Libraries\n",
    "\n",
    "We begin by importing necessary libraries for data processing, machine learning, and automated machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b976671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:17:33.807427Z",
     "iopub.status.busy": "2024-11-08T10:17:33.806948Z",
     "iopub.status.idle": "2024-11-08T10:18:04.405950Z",
     "shell.execute_reply": "2024-11-08T10:18:04.404777Z"
    },
    "papermill": {
     "duration": 30.679148,
     "end_time": "2024-11-08T10:18:04.408603",
     "exception": false,
     "start_time": "2024-11-08T10:17:33.729455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import torch\n",
    "\n",
    "# LightAutoML presets, task, and report generation\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n",
    "import os\n",
    "import reverse_geocoder as rg\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from math import radians, cos, sin, asin, sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796f210",
   "metadata": {
    "papermill": {
     "duration": 0.076306,
     "end_time": "2024-11-08T10:18:04.561702",
     "exception": false,
     "start_time": "2024-11-08T10:18:04.485396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Loading Data\n",
    "\n",
    "We load both the main dataset and an additional dataset for augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b7d2d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:18:04.718130Z",
     "iopub.status.busy": "2024-11-08T10:18:04.716653Z",
     "iopub.status.idle": "2024-11-08T10:18:11.187798Z",
     "shell.execute_reply": "2024-11-08T10:18:11.186772Z"
    },
    "papermill": {
     "duration": 6.551473,
     "end_time": "2024-11-08T10:18:11.191085",
     "exception": false,
     "start_time": "2024-11-08T10:18:04.639612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data from local directory or competition directory\n",
    "train_df = pd.read_csv('/kaggle/input/playground-series-s3e1/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/playground-series-s3e1/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/playground-series-s3e1/sample_submission.csv')\n",
    "train_df = train_df.drop('id', axis=1)\n",
    "\n",
    "# Load additional data for augmentation\n",
    "extra_data = fetch_california_housing()\n",
    "train_data2 = pd.DataFrame(extra_data['data'])\n",
    "train_data2['MedHouseVal'] = extra_data['target']\n",
    "train_data2.columns = train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914b035",
   "metadata": {
    "papermill": {
     "duration": 0.077629,
     "end_time": "2024-11-08T10:18:11.389874",
     "exception": false,
     "start_time": "2024-11-08T10:18:11.312245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Data Augmentation and Preprocessing\n",
    "\n",
    "### Concatenating Datasets\n",
    "\n",
    "We combine the additional dataset with our main training data to increase the data diversity and make our model more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d44817b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:18:11.544063Z",
     "iopub.status.busy": "2024-11-08T10:18:11.543615Z",
     "iopub.status.idle": "2024-11-08T10:18:11.589820Z",
     "shell.execute_reply": "2024-11-08T10:18:11.588566Z"
    },
    "papermill": {
     "duration": 0.127195,
     "end_time": "2024-11-08T10:18:11.592786",
     "exception": false,
     "start_time": "2024-11-08T10:18:11.465591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['generated'] = 1\n",
    "test_df['generated'] = 1\n",
    "train_data2['generated'] = 0\n",
    "train_df = pd.concat([train_df, train_data2], axis=0).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e05c4ae",
   "metadata": {
    "papermill": {
     "duration": 0.076344,
     "end_time": "2024-11-08T10:18:11.746526",
     "exception": false,
     "start_time": "2024-11-08T10:18:11.670182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Engineering\n",
    "\n",
    "#### Creating Polar Coordinates\n",
    "\n",
    "Using latitude and longitude, we create radial (`r`) and angular (`theta`) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15de6b65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:18:11.902820Z",
     "iopub.status.busy": "2024-11-08T10:18:11.902407Z",
     "iopub.status.idle": "2024-11-08T10:18:11.919559Z",
     "shell.execute_reply": "2024-11-08T10:18:11.918357Z"
    },
    "papermill": {
     "duration": 0.09816,
     "end_time": "2024-11-08T10:18:11.922167",
     "exception": false,
     "start_time": "2024-11-08T10:18:11.824007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['r'] = np.sqrt(train_df['Latitude']**2 + train_df['Longitude']**2)\n",
    "train_df['theta'] = np.arctan2(train_df['Latitude'], train_df['Longitude'])\n",
    "test_df['r'] = np.sqrt(test_df['Latitude']**2 + test_df['Longitude']**2)\n",
    "test_df['theta'] = np.arctan2(test_df['Latitude'], test_df['Longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc98bb",
   "metadata": {
    "papermill": {
     "duration": 0.077495,
     "end_time": "2024-11-08T10:18:12.077366",
     "exception": false,
     "start_time": "2024-11-08T10:18:11.999871",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Principal Component Analysis (PCA) for Dimensionality Reduction\n",
    "\n",
    "Applying PCA on latitude and longitude to generate two new components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1f6cd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:18:12.232629Z",
     "iopub.status.busy": "2024-11-08T10:18:12.231655Z",
     "iopub.status.idle": "2024-11-08T10:18:12.277998Z",
     "shell.execute_reply": "2024-11-08T10:18:12.276871Z"
    },
    "papermill": {
     "duration": 0.126642,
     "end_time": "2024-11-08T10:18:12.280641",
     "exception": false,
     "start_time": "2024-11-08T10:18:12.153999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pca(data):\n",
    "    coordinates = data[['Latitude', 'Longitude']].values\n",
    "    pca_obj = PCA().fit(coordinates)\n",
    "    pca_x = pca_obj.transform(data[['Latitude', 'Longitude']].values)[:, 0]\n",
    "    pca_y = pca_obj.transform(data[['Latitude', 'Longitude']].values)[:, 1]\n",
    "    return pca_x, pca_y\n",
    "\n",
    "train_df['pca_x'], train_df['pca_y'] = pca(train_df)\n",
    "test_df['pca_x'], test_df['pca_y'] = pca(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d2113d",
   "metadata": {
    "papermill": {
     "duration": 0.07624,
     "end_time": "2024-11-08T10:18:12.434001",
     "exception": false,
     "start_time": "2024-11-08T10:18:12.357761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Rotational Transformations\n",
    "\n",
    "Generating rotated features to provide spatial data with more variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628069b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:18:12.589130Z",
     "iopub.status.busy": "2024-11-08T10:18:12.588645Z",
     "iopub.status.idle": "2024-11-08T10:18:12.602266Z",
     "shell.execute_reply": "2024-11-08T10:18:12.600609Z"
    },
    "papermill": {
     "duration": 0.094891,
     "end_time": "2024-11-08T10:18:12.605325",
     "exception": false,
     "start_time": "2024-11-08T10:18:12.510434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def crt_crds(df):\n",
    "    df['rot_15_x'] = (np.cos(np.radians(15)) * df['Longitude']) + (np.sin(np.radians(15)) * df['Latitude'])\n",
    "    df['rot_15_y'] = (np.cos(np.radians(15)) * df['Latitude']) + (np.sin(np.radians(15)) * df['Longitude'])\n",
    "    return df\n",
    "\n",
    "train_df = crt_crds(train_df)\n",
    "test_df = crt_crds(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d443ea1",
   "metadata": {
    "papermill": {
     "duration": 0.076099,
     "end_time": "2024-11-08T10:18:12.761402",
     "exception": false,
     "start_time": "2024-11-08T10:18:12.685303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Geographic Location Encoding\n",
    "\n",
    "Using reverse geocoding to retrieve administrative regions based on latitude and longitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2474041b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:18:12.934526Z",
     "iopub.status.busy": "2024-11-08T10:18:12.934070Z",
     "iopub.status.idle": "2024-11-08T10:18:14.435268Z",
     "shell.execute_reply": "2024-11-08T10:18:14.433784Z"
    },
    "papermill": {
     "duration": 1.582247,
     "end_time": "2024-11-08T10:18:14.437954",
     "exception": false,
     "start_time": "2024-11-08T10:18:12.855707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n"
     ]
    }
   ],
   "source": [
    "def geocoder(df):\n",
    "    coordinates = list(zip(df['Latitude'], df['Longitude']))\n",
    "    results = rg.search(coordinates)\n",
    "    return results\n",
    "\n",
    "results = geocoder(train_df)\n",
    "train_df['place'] = [x['admin2'] for x in results]\n",
    "results = geocoder(test_df)\n",
    "test_df['place'] = [x['admin2'] for x in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d0c8f",
   "metadata": {
    "papermill": {
     "duration": 0.076533,
     "end_time": "2024-11-08T10:18:14.590479",
     "exception": false,
     "start_time": "2024-11-08T10:18:14.513946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Categorical Encoding for `place` Feature\n",
    "\n",
    "Encoding categorical location data to reduce dimensionality and improve training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e98fe6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:18:14.748075Z",
     "iopub.status.busy": "2024-11-08T10:18:14.747559Z",
     "iopub.status.idle": "2024-11-08T10:18:14.818048Z",
     "shell.execute_reply": "2024-11-08T10:18:14.816835Z"
    },
    "papermill": {
     "duration": 0.1524,
     "end_time": "2024-11-08T10:18:14.820944",
     "exception": false,
     "start_time": "2024-11-08T10:18:14.668544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "places = ['Los Angeles County', 'Orange County', 'Kern County',\n",
    "          'Alameda County', 'San Francisco County', 'Ventura County',\n",
    "          'Santa Clara County', 'Fresno County', 'Santa Barbara County',\n",
    "          'Contra Costa County', 'Yolo County', 'Monterey County',\n",
    "          'Riverside County', 'Napa County']\n",
    "\n",
    "train_df['place'] = train_df['place'].apply(lambda x: x if x in places else 'Other')\n",
    "test_df['place'] = test_df['place'].apply(lambda x: x if x in places else 'Other')\n",
    "train_df = pd.get_dummies(train_df)\n",
    "test_df = pd.get_dummies(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d12ea",
   "metadata": {
    "papermill": {
     "duration": 0.077214,
     "end_time": "2024-11-08T10:18:14.975264",
     "exception": false,
     "start_time": "2024-11-08T10:18:14.898050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Modeling with LightAutoML\n",
    "\n",
    "### Data Splitting\n",
    "\n",
    "Split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c66f20e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:18:15.131378Z",
     "iopub.status.busy": "2024-11-08T10:18:15.130905Z",
     "iopub.status.idle": "2024-11-08T10:18:15.135974Z",
     "shell.execute_reply": "2024-11-08T10:18:15.134782Z"
    },
    "papermill": {
     "duration": 0.085925,
     "end_time": "2024-11-08T10:18:15.138412",
     "exception": false,
     "start_time": "2024-11-08T10:18:15.052487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X = train_df.drop('MedHouseVal', axis=1)\n",
    "#y = train_df['MedHouseVal']\n",
    "#X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d751211",
   "metadata": {
    "papermill": {
     "duration": 0.076172,
     "end_time": "2024-11-08T10:18:15.291365",
     "exception": false,
     "start_time": "2024-11-08T10:18:15.215193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Setup\n",
    "\n",
    "Define key parameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a233d002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:18:15.445789Z",
     "iopub.status.busy": "2024-11-08T10:18:15.445343Z",
     "iopub.status.idle": "2024-11-08T10:18:15.453760Z",
     "shell.execute_reply": "2024-11-08T10:18:15.452571Z"
    },
    "papermill": {
     "duration": 0.088772,
     "end_time": "2024-11-08T10:18:15.456107",
     "exception": false,
     "start_time": "2024-11-08T10:18:15.367335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_THREADS = 4\n",
    "N_FOLDS = 10\n",
    "TIMEOUT = 60 * 120  # 2 hours\n",
    "TARGET_NAME = 'MedHouseVal'\n",
    "task = Task('reg', loss='mse', metric='mse')\n",
    "roles = {\n",
    "         'target': TARGET_NAME, \n",
    "         #DatetimeRole(seasonality=('d', 'm', 'wd'), base_date=True): DATE_COLUMN,\n",
    "         #\"id\": ID_COLUMN\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61f1f7",
   "metadata": {
    "papermill": {
     "duration": 0.077348,
     "end_time": "2024-11-08T10:18:15.609347",
     "exception": false,
     "start_time": "2024-11-08T10:18:15.531999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Initialization and Training\n",
    "\n",
    "Use `LightAutoML` to initialize and train a regression model with specified settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a968cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:18:15.764148Z",
     "iopub.status.busy": "2024-11-08T10:18:15.763683Z",
     "iopub.status.idle": "2024-11-08T10:27:12.363701Z",
     "shell.execute_reply": "2024-11-08T10:27:12.361975Z"
    },
    "papermill": {
     "duration": 536.681279,
     "end_time": "2024-11-08T10:27:12.367910",
     "exception": false,
     "start_time": "2024-11-08T10:18:15.686631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:18:15] Stdout logging level is INFO.\n",
      "[10:18:15] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[10:18:15] Task: reg\n",
      "\n",
      "[10:18:15] Start automl preset with listed constraints:\n",
      "[10:18:15] - time: 7200.00 seconds\n",
      "[10:18:15] - CPU: 4 cores\n",
      "[10:18:15] - memory: 16 GB\n",
      "\n",
      "[10:18:15] \u001b[1mTrain data shape: (57777, 31)\u001b[0m\n",
      "\n",
      "[10:18:23] Layer \u001b[1m1\u001b[0m train process start. Time left 7192.00 secs\n",
      "[10:18:29] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[10:18:33] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.4006654198584993\u001b[0m\n",
      "[10:18:33] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[10:18:33] Time left 7182.17 secs\n",
      "\n",
      "[10:18:43] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[10:18:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[10:21:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m-0.2646137755193394\u001b[0m\n",
      "[10:21:00] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[10:21:00] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[10:26:01] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[10:26:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[10:27:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m-0.2636821566686259\u001b[0m\n",
      "[10:27:12] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[10:27:12] Time left 6663.59 secs\n",
      "\n",
      "[10:27:12] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[10:27:12] Blending: optimization starts with equal weights and score \u001b[1m-0.27779264746166715\u001b[0m\n",
      "[10:27:12] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m-0.2612429537807223\u001b[0m, weights = \u001b[1m[0.         0.45964885 0.54035115]\u001b[0m\n",
      "[10:27:12] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m-0.2612429537807223\u001b[0m, weights = \u001b[1m[0.         0.45964885 0.54035115]\u001b[0m\n",
      "[10:27:12] Blending: no score update. Terminated\n",
      "\n",
      "[10:27:12] \u001b[1mAutoml preset training completed in 536.53 seconds\u001b[0m\n",
      "\n",
      "[10:27:12] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.45965 * (10 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.54035 * (10 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "automl = TabularAutoML(\n",
    "    task=task,\n",
    "    timeout=TIMEOUT,\n",
    "    cpu_limit=N_THREADS,\n",
    "    general_params={'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "    reader_params={'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': 42}\n",
    ")\n",
    "\n",
    "pred_tr = automl.fit_predict(train_df, roles=roles, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c3efec",
   "metadata": {
    "papermill": {
     "duration": 0.079486,
     "end_time": "2024-11-08T10:27:12.527170",
     "exception": false,
     "start_time": "2024-11-08T10:27:12.447684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Making Predictions and Submission\n",
    "\n",
    "Generate predictions for the test data and save them for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c20ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T10:27:12.693625Z",
     "iopub.status.busy": "2024-11-08T10:27:12.692909Z",
     "iopub.status.idle": "2024-11-08T10:27:28.353261Z",
     "shell.execute_reply": "2024-11-08T10:27:28.352222Z"
    },
    "papermill": {
     "duration": 15.74996,
     "end_time": "2024-11-08T10:27:28.356181",
     "exception": false,
     "start_time": "2024-11-08T10:27:12.606221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = automl.predict(test_df)\n",
    "submission['MedHouseVal'] = pred.data[:, 0]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402eded0",
   "metadata": {
    "papermill": {
     "duration": 0.07845,
     "end_time": "2024-11-08T10:27:28.513245",
     "exception": false,
     "start_time": "2024-11-08T10:27:28.434795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to use `LightAutoML` for a regression task on a housing dataset. The approach included data augmentation, feature engineering, model setup, and submission creation. LightAutoML helps streamline the machine learning process by automatically selecting and optimizing the best models for your data."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 4856522,
     "sourceId": 44629,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 808.246116,
   "end_time": "2024-11-08T10:27:31.220392",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-08T10:14:02.974276",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
